{
  "pdf_path": "data/uploads\\962ae562ca933789fddeee27ca086458.pdf",
  "text_blocks": [
    {
      "page": 1,
      "content": "Sentimental Analysis Of Twitter Data\nMr. Mayank Namdev Mahi Agrawal\nDepartment of Computer Science and Engineering Department of Computer Science and Engineering\nManipal University Jaipur Manipal University Jaipur\nJaipur, India Jaipur, India\nAbstract—Analyzing sentiment from Twitter data is crucial To improve these limitations hybrid approaches combining\nfor grasping public perception in areas like politics, healthcare, featurebasedrepresentationswithlearning-basedmodelshave\nand finance. Nonetheless the casual and disruptive character\nbeen explored.TF-IDF with Support Vector Machine (SVM)\nof Tweets that contain brevity, informal language, and sarcasm\nand Word2Vec with LSTM are evaluated to balance compu-\ncomplicateaccuratesentimentanalysis.Thisdocumentshowcases\na framework for sentiment analysis that assesses conventional tational efficiency and representation learning. Although these\nmachineeducationalframeworks,advanceddeeplearningmeth- hybrid models demonstrate improved performance compared\nods, combined strategies, and a specialized transformer model to baseline methods, they are still insufficient for capturing\nbased on Twitter data. Conventional models such as Logistic\ncomplex contextual semantics.\nRegression, Multinomial Naive Bayes and Support Vector Ma-\nRecent advances in transformer based architectures have\nchine were utilized, succeeded by a Long Short-Term Memory\nnetwork deeplearning model. Two hybrids models TF-IDF com- further improved sentiment analysis through self-attention\nbinedwithSVMandWord2VeccombinedwithLSTMenhanced mechanisms. In particular a transformer model BERTweet pre\nperformance attaining accuracies of 88.6 and 89.3 respectively. trained on Twitter data exhibits strong capability in learning\nTo boost performance even more, a BERTweet model that was\ntweet specific linguistic patterns. However despite its high\npre trained on extensive Twitter data was refined for three class\npredictiveaccuracythemodellacksinterpretability.Toaddress\nsentimentanalysisandreachedaround91accuracy.Interpretable\nAI employing SHAP was established to offer interpretability at this issue, a unified Twitter sentiment analysis framework is\nthetokenlevel.Findingsdemonstratetheefficacyoftransformer- proposed that evaluates traditional, hybrid, and transformer-\nbased sentiment examination. based models while integrating Explainable Artificial Intelli-\nIndex Terms—Sentiment Analysis, Twitter Data, BERTweet,\ngence (XAI) using SHAP to provide transparent, token-level\nHybrid Models, Explainable Artificial Intelligence, SHAP, Natu-\nexplanations of model predictions.\nral Language Processing, Transformer Models\nTo give a summary of the suggested methodology, Fig.\nI. INTRODUCTION 1 illustrates the workflow of the Twitter sentiment analysis\nSocial media sites have emerged as a key channel for framework used in this study. The figure summarizes the key\nconveyingthoughts,feelings,andresponsestorealityhappen- stages, including data preprocessing, feature extraction, base-\nings. Among these platforms Twitter stands out as a good line and hybrid modeling, BERTweet fine-tuning, sentiment\nsource of real time textual information and is extensively prediction, and explainability using SHAP, offering a clear\nutilizedforanalysisinvariousfieldsincludingsuchaspolitics, view of the overall approach.\nhealthcare,economics, finance, and social issues. Despite its\nusefulness sentiment analysis on Twitter continues to be diffi- II. LITERATUREREVIEW\ncult because of the brevity, casual and loud characteristics of\nThe analysis of sentiments expressed on Twitter has grown\ntweets, which frequently contain slang, emojis, abbreviations,\ntobeasignificantsubjectinnaturallanguageprocessingdueto\nand irony creating precision interpretation challenging.\nthisplatformmirrorspublicsentimentinstantlyandonabroad\nInitialresearchonTwittersentimentanalysispredominantly\nscale.Unliketraditionalsentimentanalysisonlongdocuments\ndepended on lexicon based approaches and conventional ma-\nTwitter data is short, informal, and highly dynamic. Tweets\nchine learning algorithms. Even though these methods are\noften include emojis, hashtags, slang, sarcasm, and rapidly\ncomputationally efficient these approaches frequently do not\nchangingdiscussiontopics,whichmakessentimentinterpreta-\nconveycontextualmeaningandsemanticconnectionsinherent\ntiondifficultandcallsforspecializedmodelingtechniques.The\nin social media text. Due to the presence of bigger Twitter\nsentiment analysis has been widely studied due to its impact\ndatasets utilized deep learning models such as Long Short-\non public opinion, finance, healthcare, and political discourse.\nTerm Memory networks were introduced to model sequential\nEarly research mainly relied on lexicon-based and traditional\npatterns.Although models based on LSTM have enhanced\nmachine learning methods. Qi and Shabrina [1] showed that\neffectivenesscomparedtoconventionalmethodstheyremained\nsuch approaches struggle to capture contextual meaning in\nlimitedinhandlinglongrangecontextandambiguousexpres-\nshort and noisy tweets, while Hassan et al. [2] demonstrated\nsions commonly found in tweets.\nthat emotion-based sentiment analysis can explain cryptocur-\nrency market trends but remains limited to specific domains."
    },
    {
      "page": 2,
      "content": "TABLEI\nTwitter Data\nSUMMARYOFTWITTERSENTIMENTANALYSISSTUDIES\nRef. Method Domain/Dataset KeyLimitation\n[1] Lexicon+ML GeneralTwitter Weak contextual\nunderstanding\nData Cleaning & Preprocessing\n[2] EmotionLexicon CryptocurrencyTweets Domain-dependentinsights\n[3] DLMNN+Hadoop Large-scaleTwitter Highcomputationalcost\n[4] ML+VADER ElectionTweets Demographicbias\n[5] ULMFiT+SVM Airline/DebateTweets Poorinterpretability\nFeature Extraction\n[7] EnsembleGCR-NN Racism-relatedTweets Task-specificmodel\n(TF-IDF / Word2Vec)\n[9] BERT-basedDL Multi-domainTwitter Black-boxbehavior\n[10] ML+TF-IDF MonkeypoxTweets Manuallabelingreliance\n[14] RoBERTa-LSTM Sentiment140,IMDb Limitedexplainability\nBaseline & Hybrid Models [16] RoBERTa-GRU AirlineTweets Increasedmodelcomplexity\n(LR, SVM, LSTM, [17] Lexicon+BERT Crime-relatedTweets Sensitivetolexiconquality\nTF-IDF + SVM, Word2Vec + LSTM) [18] XLM-TTransformer MultilingualTwitter Heavypretrainingrequired\n[15] TransformerEnsemble Cross-lingualTweets Translationerrors\n[20] Survey/Review Multi-domain Noempiricalvalidation\nBERTweet Fine-Tuning\nSentiment Prediction\n(Negative / Neutral / Positive)\nFig.2. SentimentdistributionoftheKaggleTwitterdataset.\nExplainability (SHAP)\nfor low-resource languages.\nFig.1. ProposedTwittersentimentanalysisworkflow. Despite these advances, most existing approaches prioritize\naccuracywhileofferinglimitedinterpretability.Challengesre-\nlatedtobias,domaingeneralization,andexplainabilityremain\nWiththerapidgrowthofTwitterdata,deeplearningmodels\nopen, motivating the development of explainable and domain-\nbecame increasingly popular. Neelakandan et al. [3] pro-\naware transformer-based sentiment analysis frameworks [20].\nposed a Deep Learning Modified Neural Network (DLMNN)\nTable I provides a structured summary of representative\nsupported by large-scale preprocessing to improve sentiment\nstudies on Twitter sentiment analysis, outlining the method-\nclassification accuracy.\nologiesadopted,theapplicationdomainsordatasetsexamined,\nRecent studies have focused on transformer-based and hy-\nand the principal limitations observed across traditional, deep\nbrid architectures to enhance contextual understanding. Al-\nlearning, and transformer-based approaches.\nBadanietal.[5]combinedULMFiTwithSVMtooutperform\ntraditional classifiers, while Bello et al. [9] demonstrated III. DATASETANDDATAPROCESSING\nthat BERT-based models significantly outperform Word2Vec-\nA. Dataset Description\nbased methods. Hybrid models such as RoBERTa-LSTM and\nRoBERTa-GRU further improved performance by addressing The dataset utilized in this research was obtained from\nlong-range dependencies and class imbalance [14], [16]. Kaggle and comprises of Twitter posts labeled for sentiment\nDomain-specificapplicationshavealsobeenexplored.Ben- analysis. Each tweet is labeled into one of three sentiment\ngesi et al. [10] analyzed public sentiment during the Monkey- categories: positive, neutral, or negative. Twitter was chosen\npox outbreak, and Lee et al. [7] achieved high accuracy in as the data source due to its real time nature. The dataset\ndetecting racist content using ensemble deep learning models. capturesthecharacteristicsofsocialmediatextincludingshort\nBoukabous and Azizi [17] further showed that combining sentence length, informal language, hashtags, user mentions,\nlexicon-based labeling with BERT is effective for crime- emojis, abbreviations, and domain-specific expressions. These\nrelated sentiment analysis. properties introduce significant variability and noise, making\nMultilingual sentiment analysis remains an active research the dataset both challenging and appropriate for evaluating\narea. Garg and Sharma [11] emphasized robust preprocessing traditional, hybrid, and transformer-based sentiment analysis\nfor multilingual tweets, while Barbieri et al. [18] introduced models.\nXLM-T, a Twitter-specific multilingual transformer. More re- The overall distribution of sentiment classes in the dataset\ncently, Miah et al. [15] demonstrated that ensemble-based is illustrated in Fig. 2, which shows that positive tweets form\ncross-lingual sentiment analysis using translation is effective the majority, followed by neutral and negative samples."
    },
    {
      "page": 3,
      "content": "B. Data Cleaning and Preprocessing\nRaw Twitter Data\nBeforethemodeltrainingtheunprocessedTwitterdatawent\nthrough multiple preprocessing steps to minimize noise and\nenhanceoveralldataquality.Thesestepsincludedtheremoval\nof URLs, user tags, hashtag symbols, numerical values, spe- Noise Removal\ncial characters, and extra whitespace. All text was changed (URLs, Mentions, Hashtags, Numbers, Punctuation)\nto lowercase to maintain uniformity throughout the dataset.\nTokenization was then applied to divide each tweet into\nindividual tokens, followed by stopword removal to eliminate Tokenization & Normalization\ncommonly occurring but semantically uninformative words. (Lowercasing, Stopword Removal, Lemmatization, Emoji Mapping)\nThese preprocessing operations help reduce data sparsity and\nenhancetheeffectivenessofsubsequentfeatureextractionand\nmodel learning.\nThe data preprocessing workflow is illustrated in Fig. 3. It Cleaned & Normalized Tweets\nsummarizesthekeystepsinvolvedinnoiseremoval,tokeniza-\ntion,normalization,andemojihandling,resultingincleanand Fig.3. DatapreprocessingpipelineforTwittersentimentanalysis.\nnormalizedtweetssuitableforfeatureextractionandsentiment\nclassification.\nDocument Frequency (TF-IDF), which assigns weights to\nC. Feature Extraction wordsbasedontheiroccurrenceinatweetandtheirprevalence\nthroughout the corpus. The TF-IDF value is calculated as\nTwo methods of feature extraction techniques were utilized\nfor the baseline and hybrid models. Term Frequency Inverse (cid:18) (cid:19)\nN\nDocumentFrequency(TF-IDF)wasutilizedtorepresentword TF-IDF(t,d)=TF(t,d)×log (1)\nN\nimportance based on frequency distribution throughout the t\ncorpus and Word2Vec embeddings were utilized to grasp where t denotes a term, d represents a tweet (document),\nsemantic connections among terms in a continuous vector TF(t,d) is the frequency of term t in tweet d, N is the total\nspace.TF-IDFfeatureswereprimarilyutilizedwithtraditional numberoftweetsinthedataset,andN t isthenumberoftweets\nmachinelearningmodelswhereasWord2Vecembeddingswere containing the term t. The TF-IDF formulation in Eq. (1)\ncombinedwithdeeplearningmodelstoincorporatecontextual followsthestandarddefinitionreportedin[21]andemphasizes\ninformation. Models based on transformers like BERTweet discriminativetermswhilereducingtheinfluenceoffrequently\nperform do not necessitate clear feature extraction, since they occurringwords,makingitwellsuitedforsparsesocialmedia\nacquire contextual representations straight from unprocessed text.\ntext. Three traditional machine learning classifiers—Linear Re-\ngression, Support Vector Machine , and Multinomial Naive\nD. Preparation of Data for Modeling Bayes were evaluated as baseline models for sentiment analy-\nAfter preprocessing and feature extraction the dataset was sis utilizing TF-IDF feature representations. These techniques\nsplit into training and testing subsets to assess model execu- are commonly utilized in text classification tasks and serve\ntion. The same data partitions were used consistently through as a dependable benchmark for assessing more sophisticated\nbaseline, hybrid, and transformer based models to guarantee methods.\nan equitable and reliable comparison. This standardized data LinearRegressionwasutilizedasaprobabilisticclassifierto\nprocessing pipeline contributes to the robustness and repro- learn the connection between TF-IDF features and sentiment\nducibility of the experimental results. labels. By attributing weights to separate features, the model\ncalculates the probability of a tweet fitting into a particular\nIV. METHODOLOGY sentiment category. Its straightforwardness and efficiency es-\nThis part outlines the sentiment analysis methodology tablish it as a solid foundation for high-dimensional text data.\nadopted in this study including traditional machine learn- Support Vector Machine (SVM) was employed to create an\ning models, hybrid approaches, deep learning models, and ideal decision boundary among sentiment categories within\na transformer-based model with explainability. The overall the feature space. SVM provides strong performance by max-\nworkflow is illustrated in Fig. 1. imizingthemarginbetweenclasses,especiallywhenhandling\nsparse representations like TF-IDF vectors.\nA. Traditional Machine Learning Models\nMultinomialNaiveBayeswasutilizedasagenerativemodel\nBaselineclassifierswerebasedontraditionalmachinelearn- thatreflectsworddistributionsspecifictoclassesbasedonthe\ning models because of their straightforwardness, computa- assumptionoffeatureindependence.Evenwithitssimplifying\ntional efficiency, and ease of interpretation. To allow these assumptions, this model stays computationally efficient and\nmodelstoanalyzetextualdata,tweetswereinitiallyconverted frequently produces competitive outcomes in sentiment anal-\ninto numerical formats employing Term Frequency–Inverse ysis tasks."
    },
    {
      "page": 4,
      "content": "Together, these conventional classifiers set baseline per- TABLEII\nformance metrics, allowing for significant comparisons with PERFORMANCECOMPARISONOFSENTIMENTANALYSISMODELS\nhybrid, deep learning, and transformer models examined in\nModel Accuracy Precision Recall\nsubsequent phases of the research. LinearRegression(TF-IDF) 84.2 83.6 82.9\nNa¨ıveBayes(TF-IDF) 82.5 81.9 81.2\nB. Hybrid Models SVM(TF-IDF) 86.1 85.4 84.8\nTF-IDF+SVM(Hybrid) 88.6 87.9 87.2\nTo enhance representation capability while maintaining Word2Vec+LSTM(Hybrid) 89.3 88.7 88.1\ncomputational efficiency, two hybrid models were explored. LSTM(DeepLearning) 87.4 86.8 86.1\nBERTweet(Transformer) 91.57 90.4 90.1\n1) Hybrid Model 1: TF-IDF + SVM: In the first hybrid\napproach, TF-IDF features were combined with an SVM\nclassifiertoimprovediscriminationbetweensentimentclasses.\nsentiment classification [23]. The softmax-based probability\nThismodelleveragesstatisticalfeatureweightingandmargin-\nestimation is given by\nbased classification, providing better performance than stan-\ndalone traditional models. ezc\nP(y =c|x)= (3)\n2) Hybrid Model 2: Word2Vec + LSTM: The second hy- (cid:80)C ezj\nj=1\nbrid approach merges Word2Vec embeddings with a Long\nwhere C denotes the number of sentiment classes and z\nShort-Term Memory (LSTM) network to grasp both semantic c\nrepresents the output score corresponding to class c.\nsignificance and sequential relationships in tweets. Word2Vec\nencodes words as dense vectors that maintain semantic as- E. Explainable Artificial Intelligence Using SHAP\nsociations, which are processed in sequence by the LSTM.\nToenhancemodeltransparency,ExplainableArtificialIntel-\nThroughtheuseofaninternalmemory,theLSTMrecognizes\nligence(XAI)wasincorporatedusingSHAP,whichinterprets\ncontextual and sentiment trends within the tweet that are\npredictions through additive feature attributions derived from\nfrequently overlooked by feature-based methods. This hybrid\ncooperative game theory [24]. The SHAP explanation model\napproach offers more nuanced sentiment representations than\nis defined as\nconventional classifiers while being computationally more\nefficient than models based on transformers. n\n(cid:88)\ng(x)=ϕ + ϕ (4)\n0 i\nC. Deep Learning Model\ni=1\nAn independent LSTM-based deep learning model was whereg(x)denotesthemodeloutput,ϕ representsthebase\n0\nadditionally executed to directly represent tweet sequences value, and ϕ indicates the contribution of the ith token. This\ni\nutilizing words representations. LSTM networks are capable formulation enables token-level interpretation of sentiment\nof capturing temporal dynamics dependencies, their capacity predictions and mitigates the black-box nature of transformer-\nto manage long-range context data in tweets stays restricted, based models [24].\ndriving the application of models based on transformers. Fig. 4 illustrates the BERTweet-based sentiment analysis\nworkflow,highlightingthemajorstagesfrompreprocessingto\nD. Transformer-Based Model: BERTweet\nexplainable sentiment prediction.\nTo achieve deeper contextual understanding, BERTweet, a\ntransformer-based model pre-trained on large-scale Twitter V. RESULTS,EVALUATION,ANDERRORANALYSIS\ndata, was fine-tuned for sentiment classification. BERTweet This part covers discusses the experimental results ob-\nis built upon the transformer architecture, which utilizes tained from conventional machine learning models, hybrid\nself-attention mechanisms to model contextual relationships approaches, neural network models, along with a transformer-\nbetween words in a sequence [22], [25]. The self-attention oriented sentiment analyzer. Model performance is assessed\noperation employed by the transformer is defined as through standard classification metrics to allow for an equi-\ntable and uniform comparison throughout all methods.\n(cid:18) QKT(cid:19)\nAttention(Q,K,V)=softmax √ V (2)\nd A. Evaluation Metrics\nk\nwhere Q, K, and V denote the query, key, and value Theeffectivenessofthesentimentclassificationmodelswas\nmatrices,respectively,andd representsthedimensionalityof assessed using three standard metrics: Accuracy, Precision,\nk\nand Recall, which are frequently employed in supervised\nthekeyvectors.Equation (2)followsthestandardtransformer\nclassification assignments [23]. Precision assesses the overall\nself-attention formulation [22] and adopted by BERTweet\naccuracy of forecasts, Precision measures the ratio of ac-\nfor contextual representation learning [25]. This mechanism\ncurately forecasted positive cases, while Recall assesses the\nenables the model to focus on relevant contextual information\ncapability of the model to recognize all pertinent positive\nacross the entire tweet.\ninstances.These metrics are defined as follows:\nThe final sentiment prediction is obtained using a soft-\nmax classifier Equation (3) , which converts the model out-\nTP +TN\nput scores into normalized class probabilities for multi-class Accuracy= (5)\nTP +TN +FP +FN"
    },
    {
      "page": 5,
      "content": "Twitter Dataset Collection\nData Preprocessing and Cleaning\nLabel Normalization\nTrain–Validation Split\nBERTweet Tokenization\nFig. 5. Confusion matrix of the BERTweet model for three-class sentiment\nclassification.\nClass Imbalance Handling\ncapabilitytoaccuratelygraspcontextualandsemanticnuances\ndata in Twitter information.\nBERTweet Model Fine-Tuning\nC. Error Analysis\nAlthough the overall performance is strong, several sources\nHyperparameter Optimization of classification errors were identified. Traditional and hy-\nbrid models often misclassified tweets containing sarcasm,\nidiomatic expressions, or sentiment that depends heavily on\ncontext. Neutral tweets were particularly difficult to classify\nModel Evaluation\ndue to lexical overlap with both positive and negative classes.\nWhile the BERTweet model significantly reduced such er-\nrors, misclassifications still occurred in tweets with implicit\nExplainable AI using SHAP\nsentiment or ambiguous phrasing. The use of SHAP-based\nexplainability enabled the identification of influential tokens\nresponsible for incorrect predictions, providing valuable in-\nSentiment Prediction and Interpretation\nsightintomodelbehaviorandhighlightingpotentialdirections\nforfutureimprovement.Fig.5illustratestheconfusionmatrix\nFig.4. BERTweet-basedsentimentanalysisworkflowwithexplainability. of the BERTweet model, where rows correspond to actual\nsentiment labels and columns indicate predicted labels, with\n0,1,and2representingnegative,neutral,andpositiveclasses,\nTP respectively.\nPrecision= (6)\nTP +FP\nDISCUSSION\nTP The experimental findings show distinct performance dif-\nRecall= (7) ferences among traditional, hybrid, and transformer-based\nTP +FN\nsentiment analysis methods, highlighting the intricacies of\nwhere TP, TN, FP, and FN denote true positives, true\nTwitter text along with the advantages and drawbacks of each\nnegatives, false positives, and false negatives, respectively.\nmodeling technique. Conventional machine learning models\nlikeLinearRegression,Na¨ıveBayes,andSVMserveasuseful\nB. Model Performance Comparison\nbaselinesbutareconstrainedbytheirdependenceonmanually\nTTableIIoutlinestheperformanceofeveryassessedmodels createdfeatures,limitingtheircapacitytograspcontextualand\nregardingaccuracy,precision,andrecall.Amongamongthese, implicit sentiment typically present in tweets.\nthe BERTweet model achieves the highest accuracy of 91.57 Hybrid models demonstrate steady enhancements in per-\nThe results show that traditional machine learning models formance by combining feature-based representations with\nprovide a strong baseline for sentiment classification. Hybrid learning-driven methods. TF-IDF + SVM and Word2Vec\nmodels further enhance performance by combining feature- + LSTM both obtain greater accuracy and more balanced\nbased representations with learning-based techniques. Among precision-recallmetricscomparedtoconventionalapproaches,\nall assessed methods, the transformer-driven BERTweet. The highlighting the advantages of integrating semantic data.\nmodel reaches the top scores in every metric, showcasing its Nonetheless, these improvements are modest, indicating that"
    },
    {
      "page": 6,
      "content": "hybrid models continue to face challenges with long-range [4] P. Rita, N. Anto´nio, and A. P. Afonso, “Social media discourse and\ndependencies and subtle contextual hints. voting decisions influence: Sentiment analysis in tweets during an\nelectoral period,” Social Network Analysis and Mining, vol. 13, no. 1,\nThe BERTweet model, which is based on transformers,\npp.1–19,Mar.2023.\nattainsthebestoverallperformanceonallassessmentmetrics, [5] B.AlBadani,R.Shi,andJ.Dong,“Anovelmachinelearningapproach\nleveragingpretrainingonextensiveTwitterdatasets.Evenwith for sentiment analysis on Twitter incorporating the universal language\nmodelfine-tuningandSVM,”AppliedSystemInnovation,vol.5,no.1,\nits higher accuracy, an examination of errors shows persistent\npp.1–15,Jan.2022.\ndifficulties in identifying neutral sentiment, underscoring the [6] M. S. Amin et al., “Harmonizing macro-financial factors and Twitter\nintrinsic ambiguity present in social media vocabulary. In- sentiment analysis in forecasting stock market trends,” Journal of\nComputerScienceandTechnologyStudies,Jan.2024.\ncorporatingSHAP-basedexplainabilitystrengthenstheframe-\n[7] E.Lee,F.Rustam,P.B.Washington,F.ElBarakaz,W.Aljedaani,and\nwork by offering clear, token-level insights into model pre- I.Ashraf,“Racismdetectionbyanalyzingdifferentialopinionsthrough\ndictions, fostering reliable and functional sentiment analysis sentimentanalysisoftweetsusingstackedensembleGCR-NNmodel,”\nIEEEAccess,vol.10,pp.10234–10247,2022.\nsolutions.\n[8] B.Andrian,T.Simanungkalit,I.Budi,andA.F.Wicaksono,“Sentiment\nanalysis on customer satisfaction of digital banking in Indonesia,”\nCONCLUSIONANDFUTUREWORK\nFaculty of Computer Science, University of Indonesia, vol. 13, no. 3,\nThis research explored Twitter sentiment analysis through 2022.\n[9] A.Bello,S.-C.Ng,andM.-F.Leung,“ABERTframeworkforsentiment\na structured comparison of traditional machine learning mod-\nanalysisoftweets,”Sensors,vol.23,no.1,pp.1–18,Jan.2023.\nels, hybrid approaches and a transformer based architecture. [10] S.Bengesi,T.Oladunni,R.Olusegun,andH.Audu,“Amachinelearning\nThe results show a gradual improvement in performance as sentiment analysis on Monkeypox outbreak: An extensive dataset to\nshowthepolarityofpublicopinionfromTwittertweets,”IEEEAccess,\nthe models move from simple lexical representations toward\nvol.11,pp.1–15,Feb.2023.\ncontext aware learning techniques. Classifiers such as Linear [11] N. Garg and K. Sharma, “Text pre-processing of multilingual for\nRegression, Naive Bayes and SVM provide dependable base- sentimentanalysisbasedonsocialnetworkdata,”InternationalJournal\nofElectricalandComputerEngineering,vol.12,no.1,pp.1–10,Feb.\nline outcomes. Nonetheless, their dependence on handcrafted\n2022.\nfeaturesrestricttheircapacitytomanagetheinformal,context- [12] A.R.andA.A.,“Arabictweets-basedsentimentanalysistoinvestigate\ndependent characteristics of Twitter text. theimpactofCOVID-19inKSA:Adeeplearningapproach,”BigData\nandCognitiveComputing,vol.7,no.1,pp.1–16,Jan.2023.\nHybrid models present a reasonable compromise between\n[13] M.A.PalominoandF.Aider,“Evaluatingtheeffectivenessoftextpre-\nefficiency and representation learning. The TF-IDF + SVM processinginsentimentanalysis,”AppliedSciences,vol.12,no.17,pp.\nand Word2Vec + LSTM approaches deliver more consistent 1–19,Aug.2022.\n[14] K.L.Tan,C.P.Lee,K.S.M.Anbananthen,andK.M.Lim,“RoBERTa-\nand improved results compared to traditional methods partic-\nLSTM: A hybrid model for sentiment analysis with transformer and\nularly in noisy data settings. Despite these gains the improve- recurrent neural network,” IEEE Access, vol. 10, pp. 20456–20469,\nments remain moderate indicating that hybrid models still 2022.\n[15] M.S.U.Miahetal.,“Amultimodalapproachtocross-lingualsentiment\nstruggle in capturing long range dependencies and nuanced\nanalysiswithensembleoftransformerandLLM,”ScientificReports,vol.\nsentiment variations commonly found in tweets. 14,pp.1–16,Apr.2024.\nThe BERTweet model, which is based on a transformer [16] K.L.Tan,C.P.Lee,andK.M.Lim,“RoBERTa-GRU:Ahybriddeep\narchitecture, attains the top performance overall, achieving a\nlearningmodelforenhancedsentimentanalysis,”AppliedSciences,vol.\n13,no.6,pp.1–18,Mar.2023.\nmaximum accuracy of 91.0. Its effectiveness can be attributed\n[17] M. Boukabous and M. Azizi, “Crime prediction using a hybrid senti-\nto pretraining on large scale Twitter data and its ability to ment analysis approach based on bidirectional encoder representations\nmodel contextual relationships using self attention. However from transformers,” Indonesian Journal of Electrical Engineering and\nComputerScience,vol.25,no.2,pp.1–12,Feb.2022.\nthecomplexityoftransformermodelsintroduceschallengesin\n[18] F. Barbieri, L. Espinosa-Anke, and J. Camacho-Collados, “XLM-T:\ninterpretability.Thislimitationisaddressedthroughtheuseof Multilingual language models in Twitter for sentiment analysis and\nSHAP based explainability which provides clear token level beyond,” in Proc. Language Resources and Evaluation Conf. (LREC),\n2022,pp.258–266.\ninsights into prediction behavior. [19] A. P. Rodrigues et al., “Real-time Twitter spam detection and sen-\nOverall the proposed framework strikes a balance between timent analysis using machine learning and deep learning techniques\npredictive performance and interpretability making it well (retracted),”ComputationalIntelligenceandNeuroscience,2022.\n[20] H.T.andM.M.,“Artificialintelligenceandsentimentanalysis:Areview\nsuited for real world sentiment analysis tasks. Future work\nincompetitiveresearch,”Computers,vol.12,no.2,pp.1–20,Feb.2023.\ncan explore more effective strategies for handling neutral sen- [21] A.Kumar,S.Verma,andR.Singh,“TF-IDFbasedtextrepresentation\ntiment, mitigating class imbalance, and extending the frame- forsentimentclassification,”IEEEAccess,2022.\n[22] A. Vaswani et al., “Attention is all you need,” in Advances in Neural\nwork to multilingual and cross-domain social media datasets.\nInformationProcessingSystems(NeurIPS),2017,pp.5998–6008.\n[23] C.M.Bishop,PatternRecognitionandMachineLearning.NewYork,\nREFERENCES\nNY,USA:Springer,2006.\n[1] Y.QiandZ.Shabrina,“SentimentanalysisusingTwitterdata:Acom- [24] S.M.LundbergandS.-I.Lee,“Aunifiedapproachtointerpretingmodel\nparativeapplicationoflexicon-andmachine-learning-basedapproach,” predictions,” in Advances in Neural Information Processing Systems\nSocialNetworkAnalysisandMining,vol.13,no.1,pp.1–15,Feb.2023. (NeurIPS),2017,pp.4765–4774.\n[2] M. K. Hassan, F. A. Hudaefi, and R. E. Caraka, “Mining netizen’s [25] D.Q.Nguyen,T.Vu,andA.T.Nguyen,“BERTweet:Apre-trainedlan-\nopiniononcryptocurrency:SentimentanalysisofTwitterdata,”Studies guagemodelforEnglishtweets,”inProceedingsofthe2020Conference\ninEconomicsandFinance,vol.39,no.3,pp.365–384,2022. onEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),2020,\n[3] S. Neelakandan, D. Paulraj, P. Ezhumalai, and M. Prakash, “A deep pp.9–14.\nlearningmodifiedneuralnetwork(DLMNN)basedproficientsentiment\nanalysis technique on Twitter data,” Journal of Experimental & Theo-\nreticalArtificialIntelligence,vol.36,no.3,pp.1–18,2024."
    }
  ],
  "tables": [
    {
      "page": 2,
      "table_number": 1,
      "rows": [
        [
          "Ref.",
          "Method",
          "Domain/Dataset",
          "KeyLimitation"
        ],
        [
          "[1]",
          "Lexicon+ML",
          "GeneralTwitter",
          "Weak contextual\nunderstanding"
        ],
        [
          "[2]",
          "EmotionLexicon",
          "CryptocurrencyTweets",
          "Domain-dependentinsights"
        ],
        [
          "[3]",
          "DLMNN+Hadoop",
          "Large-scaleTwitter",
          "Highcomputationalcost"
        ],
        [
          "[4]",
          "ML+VADER",
          "ElectionTweets",
          "Demographicbias"
        ],
        [
          "[5]",
          "ULMFiT+SVM",
          "Airline/DebateTweets",
          "Poorinterpretability"
        ],
        [
          "[7]",
          "EnsembleGCR-NN",
          "Racism-relatedTweets",
          "Task-specificmodel"
        ],
        [
          "[9]",
          "BERT-basedDL",
          "Multi-domainTwitter",
          "Black-boxbehavior"
        ],
        [
          "[10]",
          "ML+TF-IDF",
          "MonkeypoxTweets",
          "Manuallabelingreliance"
        ],
        [
          "[14]",
          "RoBERTa-LSTM",
          "Sentiment140,IMDb",
          "Limitedexplainability"
        ],
        [
          "[16]",
          "RoBERTa-GRU",
          "AirlineTweets",
          "Increasedmodelcomplexity"
        ],
        [
          "[17]",
          "Lexicon+BERT",
          "Crime-relatedTweets",
          "Sensitivetolexiconquality"
        ],
        [
          "[18]",
          "XLM-TTransformer",
          "MultilingualTwitter",
          "Heavypretrainingrequired"
        ],
        [
          "[15]",
          "TransformerEnsemble",
          "Cross-lingualTweets",
          "Translationerrors"
        ],
        [
          "[20]",
          "Survey/Review",
          "Multi-domain",
          "Noempiricalvalidation"
        ]
      ]
    }
  ],
  "ocr_tables": [
    {
      "page": 5,
      "image_number": 1,
      "bbox": [
        339.832,
        50.543000000000006,
        535.1824,
        204.61400000000003
      ],
      "table_text": "22000 | ° | 344 | 532\n10000\n8000\nac | 345 | 110238) | 447\n6000\n4000\n704 | 567 | ED | |\n= | 2000"
    }
  ],
  "images_and_flowcharts": [
    {
      "page": 1,
      "type": "full_page_ocr",
      "ocr_text": "Sentimental Analysis Of Twitter Data\n\nMr. Mayank Namdev\nDepartinent of Computer Science and Engineering\nManipal University Jaipur\nJaipur, India\n\nAbstract—Analyzing sentiment from Twitter data is crucial\nfor grasping public perception in areas like politics, healthcare,\nand finance. Nonetheless the casual and disruptive character\nof Tweets that contain brevity, informal language, and sarcasm\ncomplicate accurate sentiment analysis. This document showcases\na framework for sentiment analysis that assesses conventional\nmachine educational frameworks, advanced deep learning meth-\nods, combined strategies, and a specialized transformer model\nbased on Twitter data. Conventional models such as Logistic\nRegression, Multinomial Naive Bayes and Support Vector Ma-\nchine were utilized, succeeded by a Long Short-Term Memory\nnetwork deeplearning model. Two hybrids models TF-IDF com-\nbined with SVM and Word2Vec combined with LSTM enhanced\nperformance attaining accuracies of 88.6 and 89.3 respectively.\nTo boost performance even more, a BERTweet model that was\npre trained on extensive Twitter data was refined for three class\nsentiment analysis and reached around 91 accuracy. Interpretable\nAI employing SHAP was established to offer interpretability at\nthe token level. Findings demonstrate the efficacy of transformer-\nbased sentiment examination.\n\nIndex Teris—Sentiment Analysis, Twitter Data, BERTweet,\nHybrid Models, Explainable Artificial Intelligence, SHAP, Natu-\nral Language Processing, Transformer Models\n\nI. INTRODUCTION\n\nSocial media sites have emerged as a key channel for\nconveying thoughts, feelings, and responses to reality happen-\nings. Among these platforms Twitter stands out as a good\nsource of real time textual information and is extensively\nutilized for analysis in various fields including such as politics,\nhealthcare,economics, finance, and social issues. Despite its\nusefulness sentiment analysis on Twitter continues to be diffi-\ncult because of the brevity, casual and loud characteristics of\ntweets, which frequently contain slang, emojis, abbreviations,\nand irony creating precision interpretation challenging.\n\nInitial research on Twitter sentiment analysis predominantly\ndepended on lexicon based approaches and conventional ma-\nchine learning algorithms. Even though these methods are\ncomputationally efficient these approaches frequently do not\nconvey contextual meaning and semantic connections inherent\nin social media text. Due to the presence of bigger Twitter\ndatasets utilized deep learning models such as Long Short-\nTerm Memory networks were introduced to model sequential\npatterns.Although models based on LSTM have enhanced\neffectiveness compared to conventional methods they remained\nlimited in handling long range context and ambiguous expres-\nsions commonly found in tweets.\n\nMahi Agrawal\nDepartinent of Computer Science and Engineering\nManipal University Jaipur\nJaipur, India\n\nTo improve these limitations hybrid approaches combining\nfeature based representations with learning-based models have\nbeen explored.TF-IDF with Support Vector Machine (SVM)\nand Word2Vec with LSTM are evaluated to balance compu-\ntational efficiency and representation learning. Although these\nhybrid models demonstrate improved performance compared\nto baseline methods, they are still insufficient for capturing\ncomplex contextual semantics.\n\nRecent advances in transformer based architectures have\nfurther improved sentiment analysis through self-attention\nmechanisms. In particular a transformer model BERTweet pre\ntrained on Twitter data exhibits strong capability in learning\ntweet specific linguistic patterns. However despite its high\npredictive accuracy the model lacks interpretability. To address\nthis issue, a unified Twitter sentiment analysis framework is\nproposed that evaluates traditional, hybrid, and transformer-\nbased models while integrating Explainable Artificial Intelli-\ngence (XAI) using SHAP to provide transparent, token-level\nexplanations of model predictions.\n\nTo give a summary of the suggested methodology, Fig.\n1 illustrates the workflow of the Twitter sentiment analysis\nframework used in this study. The figure summarizes the key\nstages, including data preprocessing, feature extraction, base-\nline and hybrid modeling, BERTWeet fine-tuning, sentiment\nprediction, and explainability using SHAP, offering a clear\nview of the overall approach.\n\nII. LITERATURE REVIEW\n\nThe analysis of sentiments expressed on Twitter has grown\nto be a significant subject in natural language processing due to\nthis platform mirrors public sentiment instantly and on a broad\nscale. Unlike traditional sentiment analysis on long documents\nTwitter data is short, informal, and highly dynamic. Tweets\noften include emojis, hashtags, slang, sarcasm, and rapidly\nchanging discussion topics, which makes sentiment interpreta-\ntion difficult and calls for specialized modeling techniques.The\nsentiment analysis has been widely studied due to its impact\non public opinion, finance, healthcare, and political discourse.\nEarly research mainly relied on lexicon-based and traditional\nmachine learning methods. Qi and Shabrina [1] showed that\nsuch approaches struggle to capture contextual meaning in\nshort and noisy tweets, while Hassan et al. [2] demonstrated\nthat emotion-based sentiment analysis can explain cryptocur-\nrency market trends but remains limited to specific domains."
    },
    {
      "page": 2,
      "type": "full_page_ocr",
      "ocr_text": "TABLE I\nSUMMARY OF TWITTER SENTIMENT ANALYSIS STUDIES\n\nDomain / Dataset\n\nLexicon + ML General Twitter Weak contextual\nunderstanding\n\n4]\n\nData Cleaning & Preprocessing\n\nFeature Extraction\n(TF-IDF / Word2Vec)\n\n| 9] | BERT-based DL | Multi-domain Twitter Black-box behavior\n\n[14]\nLexicon + BERT\n73]\n(20)[ Survey /Review | Multi-domain\n\nBaseline & Hybrid Models\n(LR, SVM, LSTM,\n\nTF-IDF + SVM, Word2Vec + LSTM)\n\nBERTweet Fine-Tuning\nSentiment Prediction\n(Negative / Neutral / Positive)\nExplainability (SHAP)\n\nFig. 1. Proposed Twitter sentiment analysis workflow.\n\nWith the rapid growth of Twitter data, deep learning models\nbecame increasingly popular. Neelakandan et al. [3] pro-\nposed a Deep Learning Modified Neural Network (DLMNN)\nsupported by large-scale preprocessing to improve sentiment\nclassification accuracy.\n\nRecent studies have focused on transformer-based and hy-\nbrid architectures to enhance contextual understanding. Al-\nBadani et al. [5] combined ULMFiT with SVM to outperform\ntraditional classifiers, while Bello et al. [9] demonstrated\nthat BERT-based models significantly outperform Word2Vec-\nbased methods. Hybrid models such as ROBERTa-LSTM and\nRoBERTa-GRU further improved performance by addressing\nlong-range dependencies and class imbalance [14], [16].\n\nDomain-specific applications have also been explored. Ben-\ngesi et al. [10] analyzed public sentiment during the Monkey-\npox outbreak, and Lee et al. [7] achieved high accuracy in\ndetecting racist content using ensemble deep learning models.\nBoukabous and Azizi [17] further showed that combining\nlexicon-based labeling with BERT is effective for crime-\nrelated sentiment analysis.\n\nMultilingual sentiment analysis remains an active research\narea. Garg and Sharma [11] emphasized robust preprocessing\nfor multilingual tweets, while Barbieri et al. [18] introduced\nXLM-T, a Twitter-specific multilingual transformer. More re-\ncently, Miah et al. [15] demonstrated that ensemble-based\ncross-lingual sentiment analysis using translation is effective\n\nSentiment Distribution\n\nkaggle\n\n32%\n17%\n\nNeutral Negative\n\nom\n\n]\nFig. 2. Sentiment distribution of the Kaggle Twitter dataset.\n\nfor low-resource languages.\n\nDespite these advances, most existing approaches prioritize\naccuracy while offering limited interpretability. Challenges re-\nlated to bias, domain generalization, and explainability remain\nopen, motivating the development of explainable and domain-\naware transformer-based sentiment analysis frameworks [20].\n\nTable I provides a structured summary of representative\nstudies on Twitter sentiment analysis, outlining the method-\nologies adopted, the application domains or datasets examined,\nand the principal limitations observed across traditional, deep\nlearning, and transformer-based approaches.\n\nIII. DATASET AND DATA PROCESSING\nA. Dataset Description\n\nThe dataset utilized in this research was obtained from\nKaggle and comprises of Twitter posts labeled for sentiment\nanalysis. Each tweet is labeled into one of three sentiment\ncategories: positive, neutral, or negative. Twitter was chosen\nas the data source due to its real time nature. The dataset\ncaptures the characteristics of social media text including short\nsentence length, informal language, hashtags, user mentions,\nemojis, abbreviations, and domain-specific expressions. These\nproperties introduce significant variability and noise, making\nthe dataset both challenging and appropriate for evaluating\ntraditional, hybrid, and transformer-based sentiment analysis\nmodels.\n\nThe overall distribution of sentiment classes in the dataset\nis illustrated in Fig. 2, which shows that positive tweets form\nthe majority, followed by neutral and negative samples."
    },
    {
      "page": 2,
      "image_number": 1,
      "bbox": [
        389.805,
        256.63559999999995,
        485.1906,
        320.226
      ],
      "type": "image_or_flowchart_or_graph",
      "ocr_text": "Sentiment Distribution kaggle\n\nom\n\n‘Ua\n\nPositive Neutral Negative"
    },
    {
      "page": 3,
      "type": "full_page_ocr",
      "ocr_text": "B. Data Cleaning and Preprocessing\n\nBefore the model training the unprocessed Twitter data went\nthrough multiple preprocessing steps to minimize noise and\nenhance overall data quality. These steps included the removal\nof URLs, user tags, hashtag symbols, numerical values, spe-\ncial characters, and extra whitespace. All text was changed\nto lowercase to maintain uniformity throughout the dataset.\nTokenization was then applied to divide each tweet into\nindividual tokens, followed by stopword removal to eliminate\ncommonly occurring but semantically uninformative words.\nThese preprocessing operations help reduce data sparsity and\nenhance the effectiveness of subsequent feature extraction and\nmodel learning.\n\nThe data preprocessing workflow is illustrated in Fig. 3. It\nsummarizes the key steps involved in noise removal, tokeniza-\ntion, normalization, and emoji handling, resulting in clean and\nnormalized tweets suitable for feature extraction and sentiment\nclassification.\n\nC. Feature Extraction\n\nTwo methods of feature extraction techniques were utilized\nfor the baseline and hybrid models. Term Frequency Inverse\nDocument Frequency (TF-IDF) was utilized to represent word\nimportance based on frequency distribution throughout the\ncorpus and Word2Vec embeddings were utilized to grasp\nsemantic connections among terms in a continuous vector\nspace. TF-IDF features were primarily utilized with traditional\nmachine learning models whereas Word2 Vec embeddings were\ncombined with deep learning models to incorporate contextual\ninformation. Models based on transformers like BERTweet\nperform do not necessitate clear feature extraction, since they\nacquire contextual representations straight from unprocessed\ntext.\n\nD. Preparation of Data for Modeling\n\nAfter preprocessing and feature extraction the dataset was\nsplit into training and testing subsets to assess model execu-\ntion. The same data partitions were used consistently through\nbaseline, hybrid, and transformer based models to guarantee\nan equitable and reliable comparison. This standardized data\nprocessing pipeline contributes to the robustness and repro-\nducibility of the experimental results.\n\nIV. METHODOLOGY\n\nThis part outlines the sentiment analysis methodology\nadopted in this study including traditional machine learn-\ning models, hybrid approaches, deep learning models, and\na transformer-based model with explainability. The overall\nworkflow is illustrated in Fig. 1.\n\nA. Traditional Machine Learning Models\n\nBaseline classifiers were based on traditional machine learn-\ning models because of their straightforwardness, computa-\ntional efficiency, and ease of interpretation. To allow these\nmodels to analyze textual data, tweets were initially converted\ninto numerical formats employing Term Frequency—Inverse\n\nRaw Twitter Data\n\nNoise Removal\n(URLs, Mentions, Hashtags, Numbers, Punctuation)\n\nTokenization & Normalization\n(Lowercasing, Stopword Removal, Lemmatization, Emoji Mapping)\n\nCleaned & Normalized Tweets\n\nFig. 3. Data preprocessing pipeline for Twitter sentiment analysis.\n\nDocument Frequency (TF-IDF), which assigns weights to\nwords based on their occurrence in a tweet and their prevalence\nthroughout the corpus. The TF-IDF value is calculated as\nN\nTF-IDF(t, d) = TF(t, d) x log (=) (1)\nt\n\nwhere ¢ denotes a term, d represents a tweet (document),\nTF(t, d) is the frequency of term ¢ in tweet d, N is the total\nnumber of tweets in the dataset, and N; is the number of tweets\ncontaining the term ¢. The TF-IDF formulation in Eq. (1)\nfollows the standard definition reported in [21] and emphasizes\ndiscriminative terms while reducing the influence of frequently\noccurring words, making it well suited for sparse social media\ntext.\n\nThree traditional machine learning classifiers—Linear Re-\ngression, Support Vector Machine , and Multinomial Naive\nBayes were evaluated as baseline models for sentiment analy-\nsis utilizing TF-IDF feature representations. These techniques\nare commonly utilized in text classification tasks and serve\nas a dependable benchmark for assessing more sophisticated\nmethods.\n\nLinear Regression was utilized as a probabilistic classifier to\nlearn the connection between TF-IDF features and sentiment\nlabels. By attributing weights to separate features, the model\ncalculates the probability of a tweet fitting into a particular\nsentiment category. Its straightforwardness and efficiency es-\ntablish it as a solid foundation for high-dimensional text data.\n\nSupport Vector Machine (SVM) was employed to create an\nideal decision boundary among sentiment categories within\nthe feature space. SVM provides strong performance by max-\nimizing the margin between classes, especially when handling\nsparse representations like TF-IDF vectors.\n\nMultinomial Naive Bayes was utilized as a generative model\nthat reflects word distributions specific to classes based on the\nassumption of feature independence. Even with its simplifying\nassumptions, this model stays computationally efficient and\nfrequently produces competitive outcomes in sentiment anal-\nysis tasks."
    },
    {
      "page": 4,
      "type": "full_page_ocr",
      "ocr_text": "Together, these conventional classifiers set baseline per-\nformance metrics, allowing for significant comparisons with\nhybrid, deep learning, and transformer models examined in\nsubsequent phases of the research.\n\nB. Hybrid Models\n\nTo enhance representation capability while maintaining\ncomputational efficiency, two hybrid models were explored.\n\n1) Hybrid Model 1: TF-IDF + SVM: In the first hybrid\napproach, TF-IDF features were combined with an SVM\nclassifier to improve discrimination between sentiment classes.\nThis model leverages statistical feature weighting and margin-\nbased classification, providing better performance than stan-\ndalone traditional models.\n\n2) Hybrid Model 2: Word2Vec + LSTM: The second hy-\nbrid approach merges Word2Vec embeddings with a Long\nShort-Term Memory (LSTM) network to grasp both semantic\nsignificance and sequential relationships in tweets. Word2Vec\nencodes words as dense vectors that maintain semantic as-\nsociations, which are processed in sequence by the LSTM.\nThrough the use of an internal memory, the LSTM recognizes\ncontextual and sentiment trends within the tweet that are\nfrequently overlooked by feature-based methods. This hybrid\napproach offers more nuanced sentiment representations than\nconventional classifiers while being computationally more\nefficient than models based on transformers.\n\nC. Deep Learning Model\n\nAn independent LSTM-based deep learning model was\nadditionally executed to directly represent tweet sequences\nutilizing words representations. LSTM networks are capable\nof capturing temporal dynamics dependencies, their capacity\nto manage long-range context data in tweets stays restricted,\ndriving the application of models based on transformers.\n\nD. Transformer-Based Model: BERTweet\n\nTo achieve deeper contextual understanding, BERTWeet, a\ntransformer-based model pre-trained on large-scale Twitter\ndata, was fine-tuned for sentiment classification. BERTweet\nis built upon the transformer architecture, which utilizes\nself-attention mechanisms to model contextual relationships\nbetween words in a sequence [22], [25]. The self-attention\noperation employed by the transformer is defined as\n\nT\nAttention(Q, K,V) = softmax (S-) 4 (2)\n\nVik\n\nwhere Q, K, and V denote the query, key, and value\nmatrices, respectively, and d;, represents the dimensionality of\nthe key vectors. Equation (2) follows the standard transformer\nself-attention formulation [22] and adopted by BERTWeet\nfor contextual representation learning [25]. This mechanism\nenables the model to focus on relevant contextual information\nacross the entire tweet.\n\nThe final sentiment prediction is obtained using a soft-\nmax classifier Equation (3) , which converts the model out-\nput scores into normalized class probabilities for multi-class\n\nTABLE II\nPERFORMANCE COMPARISON OF SENTIMENT ANALYSIS MODELS\n\nModel Accuracy Precision Recall\n\nLinear Regression (TF-IDF) 84.2 83.6 82.9\nNaive Bayes (TF-IDF) 82.5 819 81.2\nSVM (TF-IDF) 86.1 85.4 84.8\nTF-IDF + SVM (Hybrid) 88.6 87.9 87.2\nWord2Vec + LSTM (Hybrid) 89.3 88.7 88.1\nLSTM (Deep Learning) 87.4 86.8 86.1\nBERTweet (Transformer) 91.57 90.4 90.1\n\nsentiment classification [23]. The softmax-based probability\n\nestimation is given by\neve\nPly =¢|z) = =——\njar\n\n(3)\n\nwhere C' denotes the number of sentiment classes and z,\nrepresents the output score corresponding to class ec.\n\nE. Explainable Artificial Intelligence Using SHAP\n\nTo enhance model transparency, Explainable Artificial Intel-\nligence (XAI) was incorporated using SHAP , which interprets\npredictions through additive feature attributions derived from\ncooperative game theory [24]. The SHAP explanation model\nis defined as\n\nn\n9(2) = do + 994i (4)\ni=1\n\nwhere g(x) denotes the model output, ¢9 represents the base\nvalue, and ¢, indicates the contribution of the i*” token. This\nformulation enables token-level interpretation of sentiment\npredictions and mitigates the black-box nature of transformer-\nbased models [24].\n\nFig. 4 illustrates the BERTweet-based sentiment analysis\nworkflow, highlighting the major stages from preprocessing to\nexplainable sentiment prediction.\n\nV. RESULTS, EVALUATION, AND ERROR ANALYSIS\n\nThis part covers discusses the experimental results ob-\ntained from conventional machine learning models, hybrid\napproaches, neural network models, along with a transformer-\noriented sentiment analyzer. Model performance is assessed\nthrough standard classification metrics to allow for an equi-\ntable and uniform comparison throughout all methods.\n\nA. Evaluation Metrics\n\nThe effectiveness of the sentiment classification models was\nassessed using three standard metrics: Accuracy, Precision,\nand Recall, which are frequently employed in supervised\nclassification assignments [23]. Precision assesses the overall\naccuracy of forecasts, Precision measures the ratio of ac-\ncurately forecasted positive cases, while Recall assesses the\ncapability of the model to recognize all pertinent positive\ninstances.These metrics are defined as follows:\n\nTP+TN\n\nA =\nCourncy = TP 4TN +FP+EN\n\n(6)"
    },
    {
      "page": 5,
      "type": "full_page_ocr",
      "ocr_text": "Twitter Dataset Collection\n\nData Preprocessing and Cleaning\n\nLabel Normalization\n\nTrain—Validation Split\n\nBERTweet Tokenization\n\nClass Imbalance Handling\n\nBERTweet Model Fine-Tuning\n\nHyperparameter Optimization\n\nModel Evaluation\n\nExplainable AI using SHAP\n\nSentiment Prediction and Interpretation\n\nFig. 4. BERTweet-based sentiment analysis workflow with explainability.\n\neos TP\nPrecision = TP+FP (6)\nTP\n\nwhere T'P, TN, FP, and FN denote true positives, true\nnegatives, false positives, and false negatives, respectively.\n\nB. Model Performance Comparison\n\nTTable II outlines the performance of every assessed models\nregarding accuracy, precision, and recall. Among among these,\nthe BERTweet model achieves the highest accuracy of 91.57\n\nThe results show that traditional machine learning models\nprovide a strong baseline for sentiment classification. Hybrid\nmodels further enhance performance by combining feature-\nbased representations with learning-based techniques. Among\nall assessed metheds, the transformer-driven BERTweet. The\nmodel reaches the top scores in every metric, showcasing its\n\n22000\n\n° 344 532\n10000\n8000\na 345 F238) 487\n6000\n~ 4000\na: 704 567 113178) |\n= 2000\nt t\n0 1 2\n\nFig. 5. Confusion matrix of the BERTweet model for three-class sentiment\nclassification.\n\ncapability to accurately grasp contextual and semantic nuances\ndata in Twitter information.\n\nC. Error Analysis\n\nAlthough the overall performance is strong, several sources\nof classification errors were identified. Traditional and hy-\nbrid models often misclassified tweets containing sarcasm,\nidiomatic expressions, or sentiment that depends heavily on\ncontext. Neutral tweets were particularly difficult to classify\ndue to lexical overlap with both positive and negative classes.\nWhile the BERTWeet model significantly reduced such er-\nrors, misclassifications still occurred in tweets with implicit\nsentiment or ambiguous phrasing. The use of SHAP-based\nexplainability enabled the identification of influential tokens\nresponsible for incorrect predictions, providing valuable in-\nsight into model behavior and highlighting potential directions\nfor future improvement. Fig. 5 illustrates the confusion matrix\nof the BERTweet model, where rows correspond to actual\nsentiment labels and columns indicate predicted labels, with\n0, 1, and 2 representing negative, neutral, and positive classes,\nrespectively.\n\nDISCUSSION\n\nThe experimental findings show distinct performance dif-\nferences among traditional, hybrid, and transformer-based\nsentiment analysis methods, highlighting the intricacies of\nTwitter text along with the advantages and drawbacks of each\nmodeling technique. Conventional machine learning models\nlike Linear Regression, Naive Bayes, and SVM serve as useful\nbaselines but are constrained by their dependence on manually\ncreated features, limiting their capacity to grasp contextual and\nimplicit sentiment typically present in tweets.\n\nHybrid models demonstrate steady enhancements in per-\nformance by combining feature-based representations with\nlearning-driven methods. TF-IDF + SVM and Word2Vec\n+ LSTM both obtain greater accuracy and more balanced\nprecision-recall metrics compared to conventional approaches,\nhighlighting the advantages of integrating semantic data.\nNonetheless, these improvements are modest, indicating that"
    },
    {
      "page": 5,
      "image_number": 1,
      "bbox": [
        339.832,
        50.543000000000006,
        535.1824,
        204.61400000000003
      ],
      "type": "image_or_flowchart_or_graph",
      "ocr_text": "22000\n\n° 344 532\n10000\n8000\nac 345 110238) 447\n6000\n'~ 4000\nn- 704 567 ED |\n= 2000"
    },
    {
      "page": 6,
      "type": "full_page_ocr",
      "ocr_text": "hybrid models continue to face challenges with long-range\ndependencies and subtle contextual hints.\n\nThe BERTweet model, which is based on transformers,\nattains the best overall performance on all assessment metrics,\nleveraging pretraining on extensive Twitter datasets. Even with\nits higher accuracy, an examination of errors shows persistent\ndifficulties in identifying neutral sentiment, underscoring the\nintrinsic ambiguity present in social media vocabulary. In-\ncorporating SHAP-based explainability strengthens the frame-\nwork by offering clear, token-level insights into model pre-\ndictions, fostering reliable and functional sentiment analysis\nsolutions.\n\nCONCLUSION AND FUTURE WORK\n\nThis research explored Twitter sentiment analysis through\na structured comparison of traditional machine learning mod-\nels, hybrid approaches and a transformer based architecture.\nThe results show a gradual improvement in performance as\nthe models move from simple lexical representations toward\ncontext aware learning techniques. Classifiers such as Linear\nRegression, Naive Bayes and SVM provide dependable base-\nline outcomes. Nonetheless, their dependence on handcrafted\nfeatures restrict their capacity to manage the informal, context-\ndependent characteristics of Twitter text.\n\nHybrid models present a reasonable compromise between\nefficiency and representation learning. The TF-IDF + SVM\nand Word2Vec + LSTM approaches deliver more consistent\nand improved results compared to traditional methods partic-\nularly in noisy data settings. Despite these gains the improve-\nments remain moderate indicating that hybrid models still\nstruggle in capturing long range dependencies and nuanced\nsentiment variations commonly found in tweets.\n\nThe BERTweet model, which is based on a transformer\narchitecture, attains the top performance overall, achieving a\nmaximum accuracy of 91.0. Its effectiveness can be attributed\nto pretraining on large scale Twitter data and its ability to\nmodel contextual relationships using self attention. However\nthe complexity of transformer models introduces challenges in\ninterpretability. This limitation is addressed through the use of\nSHAP based explainability which provides clear token level\ninsights into prediction behavior.\n\nOverall the proposed framework strikes a balance between\npredictive performance and interpretability making it well\nsuited for real world sentiment analysis tasks. Future work\ncan explore more effective strategies for handling neutral sen-\ntiment, mitigating class imbalance, and extending the frame-\nwork to multilingual and cross-domain social media datasets.\n\nREFERENCES\n\n{1] Y. Qi and Z. Shabrina, “Sentiment analysis using Twitter data: A com-\nparative application of lexicon- and machine-learning-based approach,”\nSocial Network Analysis and Mining, vol. 13, no. 1, pp. 1-15, Feb. 2023.\n\n[2] M. K. Hassan, F. A. Hudaefi, and R. E. Caraka, “Mining netizen’s\nopinion on cryptocurrency: Sentiment analysis of Twitter data,” Studies\nin Economics and Finance, vol. 39, no. 3, pp. 365-384, 2022.\n\n(3] S. Neelakandan, D. Paulraj, P. Ezhumalai, and M. Prakash, “A deep\nlearning modified neural network (DLMNN) based proficient sentiment\nanalysis technique on Twitter data,” Journal of Experimental & Theo-\nretical Artificial Intelligence, vol. 36, no. 3, pp. 1-18, 2024.\n\n[4]\n\n(5)\n\n6]\n\n[7]\n\n(8)\n\n)\n[10]\n\n(11)\n\n[12]\n\n[13]\n\n[14]\n\n[15]\n\n[16]\n\n[17]\n\n[18]\n\n[19]\n\n[20]\n(21)\n[22]\n[23]\n[24]\n\n[25]\n\nP. Rita, N. Anténio, and A. P. Afonso, “Social media discourse and\nvoting decisions influence: Sentiment analysis in tweets during an\nelectoral period,” Social Network Analysis and Mining, vol. 13, no. 1,\npp. 1-19, Mar. 2023.\n\nB. AlBadani, R. Shi, and J. Dong, “A novel machine learning approach\nfor sentiment analysis on Twitter incorporating the universal language\nmodel fine-tuning and SVM,” Applied System Innovation, vol. 5, no. 1,\npp. 1-15, Jan. 2022.\n\nM. S. Amin et al., “Harmonizing macro-financial factors and Twitter\nsentiment analysis in forecasting stock market trends,” Journal of\nComputer Science and Technology Studies, Jan. 2024.\n\nE. Lee, F. Rustam, P. B. Washington, F. El Barakaz, W. Aljedaani, and\nI. Ashraf, “Racism detection by analyzing differential opinions through\nsentiment analysis of tweets using stacked ensemble GCR-NN model,”\nIEEE Access, vol. 10, pp. 10234-10247, 2022.\n\nB. Andrian, T. Simanungkalit, I. Budi, and A. F Wicaksono, “Sentiment\nanalysis on customer satisfaction of digital banking in Indonesia,”\nFaculty of Computer Science, University of Indonesia, vol. 13, no. 3,\n2022\n\nA. Bello, S.-C. Ng, and M.-F. Leung, “A BERT framework for sentiment\nanalysis of tweets,” Sensors, vol. 23, no. 1, pp. 1-18, Jan. 2023.\n\nS. Bengesi, T. Oladunni, R. Olusegun, and H. Audu, “A machine learning\nsentiment analysis on Monkeypox outbreak: An extensive dataset to\nshow the polarity of public opinion from Twitter tweets,” IEEE Access,\nvol. 11, pp. 1-15, Feb. 2023.\n\nN. Garg and K. Sharma, “Text pre-processing of multilingual for\nsentiment analysis based on social network data,” International Journal\nof Electrical and Computer Engineering, vol. 12, no. 1, pp. 1-10, Feb.\n2022.\n\nA.R. and A. A., “Arabic tweets-based sentiment analysis to investigate\nthe impact of COVID-19 in KSA: A deep learning approach,” Big Data\nand Cognitive Computing, vol. 7, no. 1, pp. 1-16, Jan. 2023.\n\nM. A. Palomino and F. Aider, “Evaluating the effectiveness of text pre-\nprocessing in sentiment analysis,” Applied Sciences, vol. 12, no. 17, pp.\n1-19, Aug. 2022.\n\nK. L. Tan, C. P. Lee, K. S. M. Anbananthen, and K. M. Lim, “RoBERTa-\nLSTM: A hybrid model for sentiment analysis with transformer and\nrecurrent neural network,” JEEE Access, vol. 10, pp. 20456-20469,\n2022.\n\nM.S. U. Miah et al., “A multimodal approach to cross-lingual sentiment\nanalysis with ensemble of transformer and LLM,” Scientific Reports, vol.\n14, pp. 1-16, Apr. 2024.\n\nK. L. Tan, C. P. Lee, and K. M. Lim, “RoBERTa-GRU: A hybrid deep\nlearning model for enhanced sentiment analysis,” Applied Sciences, vol.\n13, no. 6, pp. 1-18, Mar. 2023.\n\nM. Boukabous and M. Azizi, “Crime prediction using a hybrid senti-\nment analysis approach based on bidirectional encoder representations\nfrom transformers,” Indonesian Journal of Electrical Engineering and\nComputer Science, vol. 25, no. 2, pp. 1-12, Feb. 2022.\n\nF. Barbieri, L. Espinosa-Anke, and J. Camacho-Collados, “XLM-T:\nMultilingual language models in Twitter for sentiment analysis and\nbeyond,” in Proc. Language Resources and Evaluation Conf. (LREC),\n2022, pp. 258-266.\n\nA. P. Rodrigues ef al, “Real-time Twitter spam detection and sen-\ntiment analysis using machine learning and deep learning techniques\n(retracted),” Computational Intelligence and Neuroscience, 2022.\n\nH. T. and M. M., “Artificial intelligence and sentiment analysis: A review\nin competitive research,” Computers, vol. 12, no. 2, pp. 1-20, Feb. 2023.\nA. Kumar, S. Verma, and R. Singh, “TF-IDF based text representation\nfor sentiment classification,” IEEE Access, 2022.\n\nA. Vaswani et al., “Attention is all you need,” in Advances in Neural\nInformation Processing Systems (NeurIPS), 2017, pp. 5998-6008.\n\nC. M. Bishop, Pattern Recognition and Machine Learning. New York,\nNY, USA: Springer, 2006.\n\nS. M. Lundberg and S.-I. Lee, “A unified approach to interpreting model\npredictions,” in Advances in Neural Information Processing Systems\n(NeurIPS), 2017, pp. 4765-4774.\n\nD. Q. Nguyen, T. Vu, and A. T. Nguyen, “BERTweet: A pre-trained Ian-\nguage model for English tweets,” in Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Processing (EMNLP), 2020,\npp. 9-14."
    }
  ],
  "errors": []
}